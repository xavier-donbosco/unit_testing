{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e8eee97d-6db9-4bf5-bad3-04e6384ac47a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pytest\n",
    "from pyspark.sql.functions import col, lit\n",
    "\n",
    "@pytest.fixture\n",
    "def sample_data(spark_session):\n",
    "    data = [(\"John\", 30, \"Engineer\"), (\"Alice\", 25, \"Doctor\")]\n",
    "    columns = [\"Name\", \"Age\", \"Profession\"]\n",
    "    return spark_session.createDataFrame(data, columns)\n",
    "\n",
    "def test_read_csv_remove_row(spark_session):\n",
    "    path = \"test.csv\"\n",
    "    test_df = ReadWrite.read_csv_remove_row(spark_session, path)\n",
    "    assert test_df.count() == 1\n",
    "\n",
    "def test_schema_apply_change_col(spark_session, sample_data):\n",
    "    df_schema = sample_data.schema\n",
    "    clm_rename_dic = {\"Name\": \"Full_Name\", \"Age\": \"Years\", \"Profession\": \"Job\"}\n",
    "    result_df = ReadWrite.schema_apply_change_col(sample_data, df_schema, clm_rename_dic)\n",
    "    assert sorted(result_df.columns) == sorted([\"Full_Name\", \"Years\", \"Job\"])\n",
    "\n",
    "def test_result_dfs(sample_data):\n",
    "    merge_col = [\"Name\", \"Age\"]\n",
    "    result_df = sample_data.withColumn(\"load_date\", lit(\"2024-03-20\"))\n",
    "    null_df, not_null_df = ReadWrite.result_dfs(merge_col, result_df)\n",
    "    assert null_df.count() == 0\n",
    "    assert not_null_df.count() == 2\n",
    "\n",
    "def test_add_load_date(sample_data):\n",
    "    schedule_date = \"2024-03-20\"\n",
    "    result_df = ReadWrite.add_load_date(sample_data, schedule_date)\n",
    "    assert \"load_date\" in result_df.columns\n",
    "    assert result_df.filter(col(\"load_date\") == lit(schedule_date)).count() == sample_data.count()\n",
    "\n",
    "def test_get_schema_rename_clm():\n",
    "    with pytest.raises(Exception) as excinfo:\n",
    "        ReadWrite.get_schema_rename_clm(\"non_existing_table\")\n",
    "    assert \"Given Table name not found\" in str(excinfo.value)\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "unit_testing",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
